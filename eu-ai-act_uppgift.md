### Uppgift om EU:s AI ACT
*Gjord av Fabian och Filip*  

1. Förslaget handlar om AI och diskuterar dess potentiella fördelar och risker. EU föreslår ett rättsligt ramverk för att ta itu med dessa frågor som kommer att fokusera på AI-system med hög risk. Dessa system måste uppfylla vissa krav innan de kan släppas på marknaden. Målet är att säkerställa att AI används på ett säkert och etiskt sätt. Förslaget behövs då vi inte vet alla användningsområden AI kan komma att ha än eftersom det är en väldigt ny teknik. Men det vi redan vet är att många kommer använda den, och alla kommer inte göra det på ett etiskt sätt. Några andra tekniker som också har krävt uppstyrning och reglering är bl.a. hantering av personlig data online, alltså GDPR; genmodifierade grödor och annan genteknik där fokus också ligger på säkerhet och riskbedömning; och kemikalier i både kläder och andra konsumentvaror som vi tidigare trodde var säkra. 

2. 
    * En lösning är att sätta kameror på kommunala och regionala fordon (såsom sopbilar, polisbilar osv) som har en AI-lösning som identifierar och tar bilder när fordonet kör förbi ett potthål. Man skulle även kunna använda en AI-lösning för att välja ut resurser att laga potthålen när de har identifierats. Lösningen kan till stor del följa riktlinjerna i EU:s AI ACT. De problem som kan uppstå skulle om insamling och lagring av bilder och data inte skulle ske i enlighet med GDPR då anonymisering och säker datalagring är viktigt. Det bör även vara tydligt vem som har ansvar för eventuella felaktiga identifieringar eller skador som orsakas av AI-systemet. Det är även viktigt att systemet är skyddat mot cyberattacker och obehörig åtkomst till data. Det är även viktigt att informera allmänheten om hur AI:n och datan används. 
    * Vi tror att kommunen/regionen har en ganska bra ide om vilka vägar som ska prioriteras (vägar med hög hastighet, mycket trafik och farliga förhållanden). Där det finns stora förbättringar är i förberedelsestadiet inför snöovädret. En lösning på detta problem skulle kunna vara ett AI-system som analyserar meteorologdata för att “förutspå” snöoväder, varna och se till att rätt mängd resurser finns tillgängligt och förberett. Vi ser inga stora risker med AI:n i denna lösning då ingen personlig data hanteras och den har ingen direkt påverkan på befolkningens hälsa eller välmående. Så länge man är öppen och transparent samt använder varierad data från många olika källor så att lösningen blir så robust så möjligt.
3. En lösning är att ha ett AI-system som analyserar en patients medicinska data för att hjälpa läkare att hitta och optimera den bästa behandlingen. För att minimera att onödiga kvantiteter medicin skickas ut kan även lösningen hjälpa till att hålla koll på distributionen, alltså vilka patienter som redan har fått sin medicin och när de ska få den igen. Den data lösningen behöver ha tillgång till är information om olika läkemedel, deras biverkningar, interaktioner med andra läkemedel osv. till träning och sedan också patientjournaler för individuella behandlingsplaner. En risk med det här är att AI:n kommer att hantera känslig och personlig information. Därför är det mycket viktigt att man följer dataskyddslagar såsom GDPR för att säkerställa att ingen data hamnar i fel händer. Ytterligare ett problem som kan uppstå är att AI:n tar ett radikalt felbeslut som kan komma att skada patienten istället för att hjälpa dem. Ett sätt att minimera risken för detta är att träna AI:n på en stor och varierad mängd data som inkluderar både vanliga och sällsynta åkommor, variationer, åldersgrupper mm. Dessutom ska resultaten AI:n kommer fram till alltid ses över och/eller anpassas av en läkare. För att behålla autonomin ska patienten såklart själv få bestämma om de vill att deras personliga information ska användas av lösningen eller inte.
4. Här skulle en lösning som ser över och analyserar låneansökningar kan kanske få en mer nyanserad och tydlig bild av en potentiell låntagares situation och kapacitet att betala av ett lån, och därmed kanske öka antalet som får lån. Komma med ja eller nej svar, en motivation till varför den kom fram till resultaten den gjorde. Om ansökan inte gick igenom kanske säga hur mycket låntagaren har möjlighet att låna för tillfället och ge förbättringsförslag till låntagaren, för att  öka chansen att få lån i framtiden. En risk som finns även här är datasäkerhet då känslig information hanteras. GDPR och dataskyddslagar blir återigen mycket viktiga att följa. Att inte diskriminera någon kan också vara ett problem för en AI om det inte får rätt data att träna med. Därför är det viktigt att lämna uta all irrelevant information ur träningsmaterialet och bara ha med sådant som faktiskt spelar roll för att göra en bolånebedömning. Viktigt också att vara transparent och informera användaren att hens information används och analyseras av en AI, dessutom bör AI:n kunna motivera sina val och förklara hur den kom fram till det den gjorde. Denna lösning fixar inte problemet direkt, men underlättar processen för båda parter. För att få ett så bra resultat så möjligt kan AI:ns analys ses över av en ekonom på banken.
